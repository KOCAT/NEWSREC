此代码使用天池实验室GPU模式即可复现

python版本:天池实验室默认版本3.6.4即可

 

解题思路：
1)用户画像：包含用户的基本信息、历史行为、短期行为（如：活跃度）、兴趣内容和个人偏好（如：字数偏好、设备习惯、时间习惯）等多个维度的数据，是给用户做个性化推荐的基础。
2)文章画像：包含主题、文章热度（此赛题不太有用）、字数和创建时间等。
3)特征工程：包含文章的类别属性、主题属性、关键词信息、内容分析、人群偏好和统计特征等比较全面的描述和度量，是新闻内容和质量分析的基础，也是做好用户与文章个性化匹配的基础。
a)相关性特征：可以理解为语义特征或者字面特征，用于描述用户和内容是否匹配。比较常见的匹配有：分类匹配、topic匹配、关键词匹配、媒体来源匹配等。
b)上下文特征：包括用户的位置、时间、移动设备、联网状态等，这些就是bias特征，也能由此构建一些匹配特征。
c)热度特征：包括文章的ctr、分类热度、topic热度等，这种内容热度信息不仅在推荐特征中起着重要作用，而且在用户冷启动的时候也非常有效。
d)挖掘类特征：例如协同特征、聚类特征等，这类特征并非考虑用户的历史，而是根据用户点击行为分析不同用户的相似性，比如点击相似、兴趣相似或者属于同一个类簇，从而获取到新颖的结果，扩展了模型的探索能力，也能有效的解决越拖越窄的问题。
4)召回算法：包含多个通道的召回模型，例如协同过滤（itemcf、usercf等）、主题模型、内容召回、矩阵分解等。（召回是从海量文章中，挑选一小部分文章，组成候选文章，可以降低排序的过程）
5)排序算法：对多个通道召回的内容进行统一的打分排序，选出最优的少量结果，这里常用的模型有lr、gbdt、lgb LGBMClassifier（机器学习模型）、lgb LGBMRanker（排序模型）、fm、简单加权和stacking（模型融合思路）以及DNN的一些模型（还有CTR模型（二分类模型）中的DIN（深度学习模型），排序模型中的LambdaRank(pair-wise）)。
a)基于协同过滤：汇总所有用户（user）和文章（item）的行为，利用集体智慧进行推荐。主要分为两大类，User-CF和Item-CF
b)基于embedding向量：一方面是文章实体的embedding表示，另一方面是通过word2vec等方式获取的。
c)基于DNN召回：利用深度神经网络，根据用户的基础特征和上下文环境，来模拟矩阵分解的过程
d)基于矩阵分解：协同过滤的核心是相似度计算，比较依赖用户行为，如果用户行为矩阵比较稀疏，计算结果不稳定，或者用户u没有对文章的相似度得分，可以得到很好的解决。

本代码只做了：Item-CF召回 --> 排序